{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"3ca49eca6d9e4c9f9898e693dcae9e61","deepnote_cell_type":"markdown","tags":[]},"source":["<img src = \"images/UL.png\" alt = \"Unsupervised Learning\" />\n","\n","# 0722 I05 Unsupervised Learning Bin Liao\n","\n","**How to prepare the assignment?**\n","In this assignment you will work individually and independently.\n","\n","Task 1:\n","You will create a new notebook with file name \"0722 I05 Unsupervised Learning YourFirstName LastName.ipynb\". You will include the same file name as Heading 1 in the notebook.\n","\n","You will choose a suitable open dataset of your interest to demonstrate your grasp on the tasks listed in this assignment. You can search for a dataset on [Free Data Set](https://www.interviewquery.com/blog-free-datasets/) or [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/index.php) or [Kaggle](https://www.kaggle.com/datasets). You can also choose a dataset of your interest other than the ones suggested on the given links. You cannot choose a dataset from any of the libraries in the Python. You will keep your data file in a GitHub repository.\n","**(2 Marks)**\n","\n","Task 2:\n","Please ensure that the dataset has at least three of the five data types viz. float (numeric), int (numeric), datetime64 (Date), logical (Boolean) and object (String). You must run appropriate commands to confirm and report that your dataset indeed fulfils the aforementioned requirement. You can choose to create a new column to fulfil this requirement. You can generate data using random module in the numpy or just type in a new column if it is not available in the dataset chosen by you.\n","**(2 Marks)**\n","\n","Task 3:\n","Perform exploratory data analysis using pandas and scikit library or a library of your choice to understand and describe it. Descriptions can involve five number summary, histograms, boxplots, checking for missing values, checking for outliers etc.\n","**(2 Marks)**\n","\n","Task 4:\n","(a)Scale the data using normalization and/or standardization.\n","(b)Perform Reduce the dimensionality of the data set using Principal Component Analysis (PCA).\n","(c). Create a suitable visualization to support your PCA analysis.\n","**(2 Marks)**\n","\n","Task 5:\n","(a)Use Elbow method and/or Silhouette Score Method to determine the number of clusters.\n","(b)Build and implement the K-means clustering model using scikit-learn library.\n","(c)Visualize the clusters with their centroids using any visualization library.\n","**(2 Marks)**\n","\n","\n","**How to submit your assignment?**\n","You will submit the link to the Colab notebook of your work as your submission. \n","**This is a single submission assignment. You cannot resubmit the assignment.**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Task 1: Data preparation\n","\n","In this analysis, we are using the \"Weather in Szeged 2006-2016\" dataset to demonstrate an unsupervised learning approach. The dataset consists of various weather attributes, such as temperature, humidity, wind speed, wind bearing, visibility, etc., recorded from 2006 to 2016 in Szeged, Hungary.\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"7b4c86e34866439c8fa8c4c9c89586c3","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
