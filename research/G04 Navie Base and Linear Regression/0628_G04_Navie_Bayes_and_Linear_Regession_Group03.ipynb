{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  G04 Na√Øve Bayes & Linear Regression - Group 03\n",
    "\n",
    "## Intructions\n",
    "Apply k-fold Cross Validation and Bootstrap method to a Classification model based on the data set available on https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "You need to identify whether a customer will subscribe to a term deposit or not.\n",
    "\n",
    "You need not use all the variables to build the model. You are can preprocess the data using Pandas as necessary. \n",
    "\n",
    "Build a simple model and focus on interpretation and communication of your insights from the analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01: Load the data\n",
    "Initial the project and download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import os as os\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "# Create a temporary directory in the current working directory\n",
    "tmp_dir = os.path.join(os.getcwd(), \"tmp\")\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# URL to download the zip file\n",
    "url = 'https://archive.ics.uci.edu/static/public/222/bank+marketing.zip'\n",
    "\n",
    "# Send a HTTP request to the URL of the zipfile\n",
    "response = requests.get(url)\n",
    "\n",
    "# Read the content of the file and create a BytesIO object from it\n",
    "file_object = BytesIO(response.content)\n",
    "\n",
    "# Create a zipfile object from the BytesIO\n",
    "zipfile_object = zipfile.ZipFile(file_object)\n",
    "\n",
    "# Extract the zip file\n",
    "zipfile_object.extractall(tmp_dir)\n",
    "\n",
    "# Now you have two more zips to unzip, let's do it one by one\n",
    "\n",
    "# Unzip bank.zip\n",
    "with zipfile.ZipFile(os.path.join(tmp_dir, \"bank.zip\"), 'r') as zip_ref:\n",
    "    zip_ref.extractall(tmp_dir)\n",
    "\n",
    "# Unzip bank-additional.zip\n",
    "with zipfile.ZipFile(os.path.join(tmp_dir, \"bank-additional.zip\"), 'r') as zip_ref:\n",
    "    zip_ref.extractall(tmp_dir)\n",
    "\n",
    "# Read the data files\n",
    "bank = pd.read_csv(os.path.join(tmp_dir, 'bank-full.csv'), sep=';')\n",
    "bank_additional= pd.read_csv(os.path.join(tmp_dir, 'bank-additional', 'bank-additional-full.csv'), sep=';')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02: Data Preprocessing\n",
    "Inspect, clean and preprocess the downloaded data to get it ready for the machine learning model.\n",
    "\n",
    "In the following analysis, we will focus on the bank.csv data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data type in the bank dataset.\n",
    "bank.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, the column 'y' represents the target with 'yes' meaning the client subscribed to a term deposit and 'no' meaning they did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "    # Split the data into features 'X' and target 'y'\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_bank, X_test_bank, y_train_bank, y_test_bank = preprocess_data(bank)\n",
    "X_train_bank_additional, X_test_bank_additional, y_train_bank_additional, y_test_bank_additional = preprocess_data(bank_additional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Build a Classification Model\n",
    "\n",
    "In this case, we are going to use the Logistic Regression model from the scikit-learn library, to build the Classification Model. Logistic Regression model is common use for thebinary classication problem like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for bank dataset: 0.8854362490324007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model_bank = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_bank.fit(X_train_bank, y_train_bank)\n",
    "\n",
    "\n",
    "# Use the model to predict the test data\n",
    "y_pred_bank = model_bank.predict(X_test_bank)\n",
    "\n",
    "\n",
    "# Compute accuracy\n",
    "acc_bank = accuracy_score(y_test_bank, y_pred_bank)\n",
    "\n",
    "print(f\"Accuracy for bank dataset: {acc_bank}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of appoximattely 88.54% on the test data which means that the model is correctly predicting whether a client will subscribe a term deposit around 88.54% of the time on this dataset. This is a good accuracy score.\n",
    "\n",
    "However, we could improve our model peromance with the \"Hyperparameter Tuning\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Accuracy for bank dataset with best model: 0.8880902355413026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_bank = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both the training and test data\n",
    "X_train_bank_scaled = scaler_bank.fit_transform(X_train_bank)\n",
    "X_test_bank_scaled = scaler_bank.transform(X_test_bank)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],  # lbfgs solver supports only 'l2' penalty\n",
    "}\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV to the scaled training data\n",
    "grid_search.fit(X_train_bank_scaled, y_train_bank)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Fit a logistic regression model with the best parameters to the scaled training data\n",
    "best_model = LogisticRegression(max_iter=1000, C=best_params['C'], penalty=best_params['penalty'])\n",
    "best_model.fit(X_train_bank_scaled, y_train_bank)\n",
    "\n",
    "# Use the model with the best parameters to predict the scaled test data\n",
    "y_pred_bank_best = best_model.predict(X_test_bank_scaled)\n",
    "\n",
    "# Compute accuracy\n",
    "acc_bank_best = accuracy_score(y_test_bank, y_pred_bank_best)\n",
    "\n",
    "print(f\"Accuracy for bank dataset with best model: {acc_bank_best}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our logistic regression model after hyperparameter tuning ('C': 0.1, 'penalty': 'l2') is 0.8881, which is slightly higher than the accuracy we got initially with default hyperparameters (0.8854). This means the hyperparameter tuning process improved our model's performance slightly, which is a good sign. We will keep use this model to do the k-fold Cross valiadtion and boostrap method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Apply k-fold Cross Validation\n",
    "\n",
    "Apply the sklearn's cross_val_score method to apply k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for bank dataset: [0.890517   0.8885817  0.88747581 0.890517   0.88941111 0.89245231\n",
      " 0.890517   0.89632292 0.88938053 0.89712389]\n",
      "Mean cross-validation score for bank dataset: 0.891\n",
      "Standard deviation of cross-validation score for bank dataset: 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_model.set_params(max_iter=10000)\n",
    "\n",
    "# Compute cross-validation score\n",
    "cv_scores_bank = cross_val_score(best_model, X_train_bank, y_train_bank, cv=10)\n",
    "\n",
    "print(f\"Cross-validation scores for bank dataset: {cv_scores_bank}\")\n",
    "\n",
    "# Compute mean and standard deviation of cross-validation scores\n",
    "mean_cv_scores_bank = np.mean(cv_scores_bank)\n",
    "std_cv_scores_bank = np.std(cv_scores_bank)\n",
    "\n",
    "# Print mean and standard deviation of cross-validation scores\n",
    "print(f\"Mean cross-validation score for bank dataset: {mean_cv_scores_bank:.3f}\")\n",
    "print(f\"Standard deviation of cross-validation score for bank dataset: {std_cv_scores_bank:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model demonstrated robust and consistent performance across different partitions of the training set, achieving an average accuracy of 0.891. The standard deviation of 0.003 suggests a very low variability in the model's performance across the different folds in the 5-fold cross-validation process. This implies that our model is not just fitting the data well, but also generalizing well to unseen data, which is a critical aspect of any machine learning model. Given the small standard deviation, we can expect the model's accuracy to typically lie in the range of 0.888 to 0.894 on new, unseen data. The model therefore provides a reliable tool for predicting whether a client will subscribe to a term deposit in the bank."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##: 05 Bootstrap method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample 1/100...\n",
      "Bootstrap sample 2/100...\n",
      "Bootstrap sample 3/100...\n",
      "Bootstrap sample 4/100...\n",
      "Bootstrap sample 5/100...\n",
      "Bootstrap sample 6/100...\n",
      "Bootstrap sample 7/100...\n",
      "Bootstrap sample 8/100...\n",
      "Bootstrap sample 9/100...\n",
      "Bootstrap sample 10/100...\n",
      "Bootstrap sample 11/100...\n",
      "Bootstrap sample 12/100...\n",
      "Bootstrap sample 13/100...\n",
      "Bootstrap sample 14/100...\n",
      "Bootstrap sample 15/100...\n",
      "Bootstrap sample 16/100...\n",
      "Bootstrap sample 17/100...\n",
      "Bootstrap sample 18/100...\n",
      "Bootstrap sample 19/100...\n",
      "Bootstrap sample 20/100...\n",
      "Bootstrap sample 21/100...\n",
      "Bootstrap sample 22/100...\n",
      "Bootstrap sample 23/100...\n",
      "Bootstrap sample 24/100...\n",
      "Bootstrap sample 25/100...\n",
      "Bootstrap sample 26/100...\n",
      "Bootstrap sample 27/100...\n",
      "Bootstrap sample 28/100...\n",
      "Bootstrap sample 29/100...\n",
      "Bootstrap sample 30/100...\n",
      "Bootstrap sample 31/100...\n",
      "Bootstrap sample 32/100...\n",
      "Bootstrap sample 33/100...\n",
      "Bootstrap sample 34/100...\n",
      "Bootstrap sample 35/100...\n",
      "Bootstrap sample 36/100...\n",
      "Bootstrap sample 37/100...\n",
      "Bootstrap sample 38/100...\n",
      "Bootstrap sample 39/100...\n",
      "Bootstrap sample 40/100...\n",
      "Bootstrap sample 41/100...\n",
      "Bootstrap sample 42/100...\n",
      "Bootstrap sample 43/100...\n",
      "Bootstrap sample 44/100...\n",
      "Bootstrap sample 45/100...\n",
      "Bootstrap sample 46/100...\n",
      "Bootstrap sample 47/100...\n",
      "Bootstrap sample 48/100...\n",
      "Bootstrap sample 49/100...\n",
      "Bootstrap sample 50/100...\n",
      "Bootstrap sample 51/100...\n",
      "Bootstrap sample 52/100...\n",
      "Bootstrap sample 53/100...\n",
      "Bootstrap sample 54/100...\n",
      "Bootstrap sample 55/100...\n",
      "Bootstrap sample 56/100...\n",
      "Bootstrap sample 57/100...\n",
      "Bootstrap sample 58/100...\n",
      "Bootstrap sample 59/100...\n",
      "Bootstrap sample 60/100...\n",
      "Bootstrap sample 61/100...\n",
      "Bootstrap sample 62/100...\n",
      "Bootstrap sample 63/100...\n",
      "Bootstrap sample 64/100...\n",
      "Bootstrap sample 65/100...\n",
      "Bootstrap sample 66/100...\n",
      "Bootstrap sample 67/100...\n",
      "Bootstrap sample 68/100...\n",
      "Bootstrap sample 69/100...\n",
      "Bootstrap sample 70/100...\n",
      "Bootstrap sample 71/100...\n",
      "Bootstrap sample 72/100...\n",
      "Bootstrap sample 73/100...\n",
      "Bootstrap sample 74/100...\n",
      "Bootstrap sample 75/100...\n",
      "Bootstrap sample 76/100...\n",
      "Bootstrap sample 77/100...\n",
      "Bootstrap sample 78/100...\n",
      "Bootstrap sample 79/100...\n",
      "Bootstrap sample 80/100...\n",
      "Bootstrap sample 81/100...\n",
      "Bootstrap sample 82/100...\n",
      "Bootstrap sample 83/100...\n",
      "Bootstrap sample 84/100...\n",
      "Bootstrap sample 85/100...\n",
      "Bootstrap sample 86/100...\n",
      "Bootstrap sample 87/100...\n",
      "Bootstrap sample 88/100...\n",
      "Bootstrap sample 89/100...\n",
      "Bootstrap sample 90/100...\n",
      "Bootstrap sample 91/100...\n",
      "Bootstrap sample 92/100...\n",
      "Bootstrap sample 93/100...\n",
      "Bootstrap sample 94/100...\n",
      "Bootstrap sample 95/100...\n",
      "Bootstrap sample 96/100...\n",
      "Bootstrap sample 97/100...\n",
      "Bootstrap sample 98/100...\n",
      "Bootstrap sample 99/100...\n",
      "Bootstrap sample 100/100...\n",
      "Mean bootstrap score for bank dataset: 0.886454716355192\n",
      "Standard deviation of bootstrap score for bank dataset: 0.0011369387881935305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize a list to store all bootstrap sample scores\n",
    "bootstrap_scores = []\n",
    "\n",
    "# Number of bootstrap samples to create\n",
    "n_bootstrap = 100\n",
    "\n",
    "# For each bootstrap sample\n",
    "for i in range(n_bootstrap):\n",
    "    print(f\"Bootstrap sample {i+1}/{n_bootstrap}...\")\n",
    "    # Create a bootstrap sample from the training set\n",
    "    X_train_boot, y_train_boot = resample(X_train_bank, y_train_bank, replace=True)\n",
    "    \n",
    "    # Fit the model on the bootstrap sample\n",
    "    best_model.fit(X_train_boot, y_train_boot)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_boot = best_model.predict(X_test_bank)\n",
    "    \n",
    "    # Compute accuracy and append to the list of scores\n",
    "    score = accuracy_score(y_test_bank, y_pred_boot)\n",
    "    bootstrap_scores.append(score)\n",
    "\n",
    "# Compute the mean and standard deviation of the bootstrap scores\n",
    "mean_bootstrap_score = np.mean(bootstrap_scores)\n",
    "std_bootstrap_score = np.std(bootstrap_scores)\n",
    "\n",
    "print(f\"Mean bootstrap score for bank dataset: {mean_bootstrap_score}\")\n",
    "print(f\"Standard deviation of bootstrap score for bank dataset: {std_bootstrap_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap method was applied to assess the stability and performance of our logistic regression model on the bank dataset. The mean bootstrap score, or the average accuracy of the model across multiple bootstrap samples, was approximately 0.886. This suggests that, on average, our model correctly classifies around 88.6% of instances in the 100 bootstrap samples.\n",
    "\n",
    "The standard deviation of the bootstrap scores, a measure of variability or dispersion of the scores, was approximately 0.00114. This relatively low standard deviation indicates that the performance of our model is consistent across different bootstrap samples. In other words, our model's performance does not significantly change or deviate with different sets of data sampled from the original dataset.\n",
    "\n",
    "These results, collectively, suggest that our logistic regression model is stable and robust in its performance, showing consistent high accuracy across different bootstrap samples of the bank dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06: Interpretation and communication of your insights\n",
    "\n",
    "Based on the evaluations and tests performed on the **bank.csv** dataset, we can conclude the following:\n",
    "\n",
    "1.   **Performance of the Model:** Our logistic regression model performs quite well with an accuracy of approximately 88.6%, as observed in both cross-validation and bootstrap analyses. This indicates that our model correctly classifies around 88.6% of the instances, suggesting a high level of prediction accuracy.\n",
    "2.   **Comparison to Baseline:** In terms of comparison to a baseline model, our logistic regression model performs significantly better than a simple random guessing model, which would only have an accuracy of 50%. Our model, therefore, offers a substantial improvement in predictive ability over a simple guess or naive baseline model.\n",
    "3. **Important Features:** Unfortunately, without explicit feature importance results from the logistic regression model, it's difficult to directly interpret which features are most influential in predicting customer behavior. However, typically in a banking scenario, features like age, job type, balance, housing, loan, contact, month, day of the week, duration of contact, and number of contacts performed during the campaign can be significant predictors. A separate analysis could be conducted to specifically extract feature importance from the logistic regression model. In the feautre, we could run the logistic regression model on the \"bank-additonal\" data set which contaions more attributes would generated differnt results.\n",
    "4. **Insights about Customers:** ue to the nature of the logistic regression model, interpreting the specific characterizations of customers who are likely to subscribe to a term deposit is challenging without further analysis. A deeper dive into the coefficients of the logistic regression model could provide insights on the features that increase the odds of a customer subscribing to a term deposit. Moreover, combining this model with an exploratory data analysis could potentially reveal important insights about the customers, like certain job types or age groups are more inclined to subscribe, or customers contacted during specific months have a higher likelihood of subscription, and so on.\n",
    "\n",
    "In conclusion, the logistic regression model built has shown robust and reliable performance in predicting whether a bank's clients will subscribe to a term deposit or not. Although the feature importance is not directly interpretable from the model, further analysis could provide deeper insights that would be valuable for the bank's marketing strategy and customer understanding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
